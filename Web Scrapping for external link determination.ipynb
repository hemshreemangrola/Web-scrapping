{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>About Webscraper:</b>\n",
    "\n",
    "This webscrapper can be used to extract valid URL's (code=200) from within a webpage<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import urllib3 \n",
    "from urllib.request import urlopen \n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import random\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = ()\n",
    "random.seed(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type your link here, I have tried Kaggle.com\n",
    "ink = \"https://www.kaggle.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExternalLink(bsObj, excludeUrl):\n",
    "    externalLink = []\n",
    "    for link in bsObj.findAll(\"a\", href=re.compile(\"^(http|www)((?!\"+excludeUrl+\").)*$\")):\n",
    "        if link.attrs['href'] is not None:\n",
    "            if link.attrs['href'] not in externalLink:\n",
    "                externalLink.append(link.attrs['href'])\n",
    "    return externalLink\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/host 2018-05-07 15:08:33.383060\n",
      "http://blog.kaggle.com/ 2018-05-07 15:08:34.083798\n",
      "https://www.kaggle.com/inclass 2018-05-07 15:08:34.369085\n"
     ]
    }
   ],
   "source": [
    "extLink = set()\n",
    "html = urlopen(ink)\n",
    "domain = urlparse(ink).scheme+\"://\"+urlparse(ink).netloc\n",
    "bsObj = BeautifulSoup(html)\n",
    "externalLink = getExternalLink(bsObj, domain)\n",
    "csvFile = []\n",
    "for link in externalLink:\n",
    "    if link not in extLink:\n",
    "        extLink.add(link)\n",
    "        http = urllib3.PoolManager()\n",
    "        response = http.request('GET',ink)\n",
    "        if (response.status == 200):\n",
    "            ourFile = (link, \"Valid\", datetime.datetime.now())\n",
    "            print(link, datetime.datetime.now())\n",
    "            csvFile.append(ourFile)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for all the valid url's\n",
    "df = pd.DataFrame(csvFile, columns=['links', 'Valid or not','Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "      <th>Valid or not</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.kaggle.com/host</td>\n",
       "      <td>Valid</td>\n",
       "      <td>2018-05-07 15:08:33.383060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://blog.kaggle.com/</td>\n",
       "      <td>Valid</td>\n",
       "      <td>2018-05-07 15:08:34.083798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.kaggle.com/inclass</td>\n",
       "      <td>Valid</td>\n",
       "      <td>2018-05-07 15:08:34.369085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            links Valid or not                       Time\n",
       "0     https://www.kaggle.com/host        Valid 2018-05-07 15:08:33.383060\n",
       "1         http://blog.kaggle.com/        Valid 2018-05-07 15:08:34.083798\n",
       "2  https://www.kaggle.com/inclass        Valid 2018-05-07 15:08:34.369085"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataset to the csv file\n",
    "df.to_csv('links.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Reference: Web Scarpping using python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
